{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce813621",
   "metadata": {},
   "source": [
    "# Run anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5525f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup\n",
    "%pip install -e .. -q\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load default config\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from metro_disruptions_intelligence.detect.streaming_iforest import StreamingIForestDetector\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "config_path = project_root / \"configs\" / \"iforest_default.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "**Note:** `StreamingIForestDetector` uses a default `subsample_size` of 256.\n",
    "Running it on fewer observations (like the small example below) will\n",
    "yield zero anomaly scores. For small samples you can pass a custom\n",
    "configuration:\n",
    "```python\n",
    "from metro_disruptions_intelligence.detect import IForestConfig\n",
    "det = StreamingIForestDetector(IForestConfig(subsample_size=50))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b5985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Choose processed features root\n",
    "project_root = Path.cwd().parent\n",
    "processed_root = project_root / \"data\" / \"stations_features_time_series\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bb77d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "The features should be stored in `data/stations_features_time_series` as described in the documentation.\n",
    "If this directory is empty you must generate the Parquet files first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a663fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4a. Train detector on stored feature files and save model\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "train_start = datetime(2023, 5, 1, 0, 0)\n",
    "train_end = train_start + timedelta(hours=2)\n",
    "det = StreamingIForestDetector(config_path)\n",
    "for ts in range(int(train_start.timestamp()), int(train_end.timestamp()), 60):\n",
    "    dt = datetime.fromtimestamp(ts)\n",
    "    p = (\n",
    "        processed_root\n",
    "        / f\"year={dt.year:04d}\"\n",
    "        / f\"month={dt.month:02d}\"\n",
    "        / f\"day={dt.day:02d}\"\n",
    "        / f\"stations_feats_{dt:%Y-%d-%m-%H-%M}.parquet\"\n",
    "    )\n",
    "    if not p.exists():\n",
    "        continue\n",
    "    df = pd.read_parquet(p)\n",
    "    det.score_and_update(df)\n",
    "det.save(\"iforest_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd2fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Stream 2 hours of feature data\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start = datetime(2023, 5, 1, 0, 0)\n",
    "end = start + timedelta(hours=2)\n",
    "rows = []\n",
    "det = StreamingIForestDetector(config_path)\n",
    "for ts in range(int(start.timestamp()), int(end.timestamp()), 60):\n",
    "    dt = datetime.fromtimestamp(ts)\n",
    "    f = (\n",
    "        processed_root\n",
    "        / f\"year={dt.year:04d}\"\n",
    "        / f\"month={dt.month:02d}\"\n",
    "        / f\"day={dt.day:02d}\"\n",
    "        / f\"stations_feats_{dt:%Y-%d-%m-%H-%M}.parquet\"\n",
    "    )\n",
    "    if not f.exists():\n",
    "        continue\n",
    "    df = pd.read_parquet(f)\n",
    "    out = det.score_and_update(df, explain=True)\n",
    "    rows.append(out)\n",
    "scores = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b57b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Histogram of anomaly_score\n",
    "plt.hist(scores[\"anomaly_score\"], bins=20)\n",
    "plt.xlabel(\"score\")\n",
    "plt.ylabel(\"count\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23073ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Top-10 anomalies with SHAP explanations\n",
    "top10 = scores.nlargest(10, \"anomaly_score\").copy()\n",
    "top10[\"shap_top3\"] = top10[\"shap_top3_json\"].apply(json.loads)\n",
    "top10[[\"ts\", \"stop_id\", \"anomaly_score\", \"shap_top3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1bf86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Mean anomaly_score over time\n",
    "scores[\"dt\"] = pd.to_datetime(scores[\"ts\"], unit=\"s\")\n",
    "mean_series = scores.groupby(\"dt\")[\"anomaly_score\"].mean()\n",
    "mean_series.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27cfac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Tune hyper-parameters via CLI\n",
    "!poetry run mdi tune-iforest \\\n",
    "+        --processed-root data/stations_features_time_series \\\n",
    "+        --start 2023-05-01T00:00:00Z \\\n",
    "+        --end 2023-05-01T02:00:00Z\n",
    "print(Path(\"iforest_best.yaml\").read_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}