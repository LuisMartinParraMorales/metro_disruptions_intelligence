{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce813621",
   "metadata": {},
   "source": [
    "# Run anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5525f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup\n",
    "%pip install -e .. -q\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ca21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load default config\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from metro_disruptions_intelligence.detect.streaming_iforest import StreamingIForestDetector\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "config_path = project_root / \"configs\" / \"iforest_default.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "**Note:** `StreamingIForestDetector` uses a default `subsample_size` of 256.\n",
    "Running it on fewer observations (like the small example below) will\n",
    "yield zero anomaly scores. For small samples you can pass a custom\n",
    "configuration:\n",
    "```python\n",
    "from metro_disruptions_intelligence.detect import IForestConfig\n",
    "det = StreamingIForestDetector(IForestConfig(subsample_size=50))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54b5985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Choose processed features root\n",
    "project_root = Path.cwd().parent\n",
    "processed_root = project_root / \"data\" / \"stations_features_time_series\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85bb77d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luis.ParraMorales\\GitProjects\\metro_disruptions_intelligence\\data\\stations_features_time_series\n"
     ]
    }
   ],
   "source": [
    "print(processed_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "The features should be stored in `data/stations_features_time_series` as described in the documentation.\n",
    "If this directory is empty you must generate the Parquet files first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a663fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4a. Train detector on stored feature files and save model\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "train_start = datetime(2023, 5, 1, 0, 0)\n",
    "train_end = train_start + timedelta(hours=2)\n",
    "det = StreamingIForestDetector(config_path)\n",
    "for ts in range(int(train_start.timestamp()), int(train_end.timestamp()), 60):\n",
    "    dt = datetime.fromtimestamp(ts)\n",
    "    p = (\n",
    "        processed_root\n",
    "        / f\"year={dt.year:04d}\"\n",
    "        / f\"month={dt.month:02d}\"\n",
    "        / f\"day={dt.day:02d}\"\n",
    "        / f\"stations_feats_{dt:%Y-%d-%m-%H-%M}.parquet\"\n",
    "    )\n",
    "    if not p.exists():\n",
    "        continue\n",
    "    df = pd.read_parquet(p)\n",
    "    det.score_and_update(df)\n",
    "det.save(\"iforest_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebdd2fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Stream 2 hours of feature data\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start = datetime(2023, 5, 1, 0, 0)\n",
    "end = start + timedelta(hours=2)\n",
    "rows = []\n",
    "det = StreamingIForestDetector(config_path)\n",
    "for ts in range(int(start.timestamp()), int(end.timestamp()), 60):\n",
    "    dt = datetime.fromtimestamp(ts)\n",
    "    f = (\n",
    "        processed_root\n",
    "        / f\"year={dt.year:04d}\"\n",
    "        / f\"month={dt.month:02d}\"\n",
    "        / f\"day={dt.day:02d}\"\n",
    "        / f\"stations_feats_{dt:%Y-%d-%m-%H-%M}.parquet\"\n",
    "    )\n",
    "    if not f.exists():\n",
    "        continue\n",
    "    df = pd.read_parquet(f)\n",
    "    out = det.score_and_update(df, explain=True)\n",
    "    rows.append(out)\n",
    "scores = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b57b03d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'anomaly_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 5. Histogram of anomaly_score\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(\u001b[43mscores\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manomaly_score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n",
      "File \u001b[1;32mc:\\Users\\Luis.ParraMorales\\AppData\\Local\\miniforge3\\envs\\mdi_env\\lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Luis.ParraMorales\\AppData\\Local\\miniforge3\\envs\\mdi_env\\lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'anomaly_score'"
     ]
    }
   ],
   "source": [
    "# 5. Histogram of anomaly_score\n",
    "plt.hist(scores[\"anomaly_score\"], bins=20)\n",
    "plt.xlabel(\"score\")\n",
    "plt.ylabel(\"count\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23073ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Top-10 anomalies with SHAP explanations\n",
    "top10 = scores.nlargest(10, \"anomaly_score\").copy()\n",
    "top10[\"shap_top3\"] = top10[\"shap_top3_json\"].apply(json.loads)\n",
    "top10[[\"ts\", \"stop_id\", \"anomaly_score\", \"shap_top3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1bf86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Mean anomaly_score over time\n",
    "scores[\"dt\"] = pd.to_datetime(scores[\"ts\"], unit=\"s\")\n",
    "mean_series = scores.groupby(\"dt\")[\"anomaly_score\"].mean()\n",
    "mean_series.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27cfac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Tune hyper-parameters via CLI\n",
    "!poetry run mdi tune-iforest \\\n",
    "+        --processed-root data/stations_features_time_series \\\n",
    "+        --start 2023-05-01T00:00:00Z \\\n",
    "+        --end 2023-05-01T02:00:00Z\n",
    "print(Path(\"iforest_best.yaml\").read_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
